{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6799,"databundleVersionId":4225553,"sourceType":"competition"},{"sourceId":4337143,"sourceType":"datasetVersion","datasetId":2553189}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.models import resnet50\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport numpy as np\nfrom tqdm import tqdm\nimport os\nfrom PIL import Image\nimport cv2\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport random\n\nclass Conf:\n    train_dir = '/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train'\n    val_dir = '/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/val'\n    batch_size = 64\n    num_workers = 4\n    num_epochs = 100\n    learning_rate = 1e-3\n    max_lr = 1e-2\n    image_size = 224\n    num_classes = 1000","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Albumentations transformations\ntrain_transforms = A.Compose([\n    A.RandomResizedCrop(height=Conf.image_size, width=Conf.image_size),\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(p=0.2),\n    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n    A.CoarseDropout(max_holes=8, max_height=8, max_width=8, fill_value=0, p=0.2),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2(),\n])\n\nval_transforms = A.Compose([\n    A.Resize(Conf.image_size, Conf.image_size),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2(),\n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, image_dir, transform=None):\n        self.image_dir = image_dir\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n        \n        subdirs = [os.path.join(image_dir, d) for d in os.listdir(image_dir)\n                  if os.path.isdir(os.path.join(image_dir, d))]\n        self.class_to_idx = {os.path.basename(d): idx for idx, d in enumerate(sorted(subdirs))}\n        \n        for d in subdirs:\n            class_idx = self.class_to_idx[os.path.basename(d)]\n            for fname in os.listdir(d):\n                if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n                    self.image_paths.append(os.path.join(d, fname))\n                    self.labels.append(class_idx)\n                    \n        print(f\"Loaded {len(self.image_paths)} images from {image_dir}\")\n        print(f\"Number of unique labels: {len(set(self.labels))}\")\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        \n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image, label\n\n# Create datasets and dataloaders\ndef create_data_loaders(train_dir, batch_size, num_workers, train_transforms, val_transforms):\n    # Create full dataset\n    full_dataset = ImageDataset(train_dir, transform=train_transforms)\n    \n    # Calculate splits\n    total_size = len(full_dataset)\n    train_size = int(0.7 * total_size)\n    val_size = total_size - train_size\n    \n    # Split dataset\n    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n    \n    # Override transforms\n    train_dataset.dataset.transform = train_transforms\n    val_dataset.dataset.transform = val_transforms\n    \n    # Create dataloaders\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True\n    )\n    \n    return train_loader, val_loader","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_one_epoch(model, train_loader, criterion, optimizer, scheduler, epoch):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{Conf.num_epochs}')\n    for batch_idx, (images, labels) in enumerate(pbar):\n        images, labels = images.cuda(), labels.cuda()\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n        pbar.set_postfix({\n            'loss': f'{running_loss/(batch_idx+1):.3f}',\n            'acc': f'{100.*correct/total:.2f}%',\n            'lr': f'{scheduler.get_last_lr()[0]:.6f}'\n        })\n\n    epoch_loss = running_loss / len(train_loader)\n    epoch_acc = 100. * correct / total\n    return epoch_loss, epoch_acc,model\n\n@torch.no_grad()\ndef validate(model, val_loader, criterion, epoch):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    pbar = tqdm(val_loader, desc='Validation')\n    for batch_idx, (images, labels) in enumerate(pbar):\n        images, labels = images.cuda(), labels.cuda()\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n        pbar.set_postfix({\n            'loss': f'{running_loss/(batch_idx+1):.3f}',\n            'acc': f'{100.*correct/total:.2f}%'\n        })\n\n    val_loss = running_loss / len(val_loader)\n    val_acc = 100. * correct / total\n    return val_loss, val_acc,model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main():\n    # Set device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n\n    train_loader, val_loader = create_data_loaders(\n        train_dir=Conf.train_dir,\n        batch_size=Conf.batch_size,\n        num_workers=Conf.num_workers,\n        train_transforms=train_transforms,\n        val_transforms=val_transforms\n    )\n\n    # Initialize model\n    print(\"\\nInitializing Model...\")\n    model = resnet50(weights=None, num_classes=Conf.num_classes)\n    model = model.to(device)\n\n    # Initialize weights\n    def init_weights(m):\n        if isinstance(m, nn.Conv2d):\n            nn.init.xavier_uniform_(m.weight)\n            if m.bias is not None:\n                nn.init.zeros_(m.bias)\n        elif isinstance(m, nn.BatchNorm2d):\n            nn.init.ones_(m.weight)\n            nn.init.zeros_(m.bias)\n        elif isinstance(m, nn.Linear):\n            nn.init.xavier_uniform_(m.weight)\n            nn.init.zeros_(m.bias)\n\n    model.apply(init_weights)\n    print(\"Initialized model weights using Xavier/Glorot initialization\")\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=Conf.learning_rate)\n\n    total_steps = len(train_loader) * Conf.num_epochs\n    scheduler = optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        max_lr=Conf.max_lr,\n        total_steps=total_steps,\n        pct_start=0.3,\n        anneal_strategy='cos'\n    )\n\n    # Training loop\n    print(\"\\nStarting Training...\")\n    best_val_acc = 0\n\n    for epoch in range(Conf.num_epochs):\n        train_loss, train_acc,model = train_one_epoch(\n            model, train_loader, criterion, optimizer, scheduler, epoch\n        )\n\n        val_loss, val_acc,model = validate(model, val_loader, criterion, epoch)\n\n        print(f'\\nEpoch {epoch+1}/{Conf.num_epochs} Summary:')\n        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n        print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': scheduler.state_dict(),\n                'best_val_acc': best_val_acc,\n            }, 'best_resnet50.pth')\n            print(f\"Saved new best model with validation accuracy: {val_acc:.2f}%\")\n\n        print('-' * 60)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}